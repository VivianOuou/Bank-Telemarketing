

## **客户聚类分析报告：基于K-Prototypes聚类方法**

### **1. 数据预处理**

数据预处理是聚类分析中的关键步骤，目的是清洗和转化数据，使其适合聚类算法进行分析。在本次分析中，数据预处理包括了缺失值填充、对数转换、标准化数值型特征以及对类别型特征的独热编码。以下是数据预处理的主要步骤：

#### **1.1 处理缺失值**

首先，我们处理了数据集中的缺失值。在数据集中，`job`、`education` 和 `contact` 特征包含了缺失值，这些特征我们使用了“未知”类别进行填充，以确保数据完整性。同时，我们删除了缺失值较多的特征 `poutcome`，因为该变量的缺失值占比较高，无法为聚类分析提供有意义的信息。

#### **1.2 连续变量的对数转换**

数据集中的一些连续变量（如 `balance`、`duration`、`campaign`、`pdays` 和 `previous`）具有右偏的分布，这会导致聚类算法无法有效识别客户群体。为了减小极端值的影响，我们对这些变量应用了对数转换（`log(x+1)`），使其分布更加接近正态分布，从而提高聚类结果的稳定性和准确性。特别地，对于包含零值的变量，我们使用了移位的对数转换方法（`log1p(x - min(x) + 1)`），确保了数据的正态化处理。

#### **1.3 标准化数值型特征**

在进行聚类之前，对数值型特征进行了标准化处理，使用了 `StandardScaler` 使其具有均值为 0，标准差为 1 的标准正态分布。标准化确保了不同数值型特征之间在聚类计算时具有相同的量纲，避免了某些特征的量纲差异对聚类结果的主导作用。

#### **1.4 类别型特征的独热编码**

类别型特征（如 `job`、`marital`、`education` 等）需要转换为数值型，以便 K-Prototypes 聚类算法能够处理。我们使用了独热编码（One-Hot Encoding）方法，将类别型变量转换为多个二元特征，表示各个类别的存在与否。

### **2. 使用K-Prototypes聚类方法**

#### **2.1 K-Prototypes聚类方法原理与K-Means对比**

K-Prototypes聚类方法是针对混合数据（数值型和类别型数据）设计的聚类算法，它结合了K-Means和K-Modes算法的优点。K-Means算法只能处理数值型数据，而K-Modes算法则专门用于类别型数据。K-Prototypes通过以下方式结合了这两种算法：

* **数值型数据**：使用 **欧几里得距离**（Euclidean Distance）来度量数据点之间的相似性。
* **类别型数据**：使用 **模式匹配**（Mode Matching）来度量数据点的相似性，即通过计算类别型特征的众数来判断数据点之间的相似性。

K-Prototypes聚类方法在处理混合数据时，能够有效地对数值型和类别型特征进行加权计算，确保聚类结果的准确性。

与K-Means的对比：

* **K-Means**：仅适用于数值型数据，且聚类时通过最小化 **平方欧几里得距离** 来优化簇的分配。
* **K-Prototypes**：适用于数值型和类别型混合数据，通过欧几里得距离和模式匹配的结合来优化聚类结果。

#### **2.2 为什么选择K-Prototypes聚类方法**

选择K-Prototypes聚类方法的原因在于数据集的混合特性。该数据集包含了数值型特征（如 `age`、`balance`）和类别型特征（如 `job`、`marital`）。传统的K-Means算法无法直接处理类别型数据，而K-Prototypes能够同时处理数值型和类别型特征，且能够提供更准确的聚类结果。

K-Prototypes的优势包括：

* 能够有效处理类别型和数值型数据。
* 结合了K-Means和K-Modes的优点，确保了对混合数据集的处理效果。
* 聚类结果更符合实际业务需求，可以为银行的客户分群提供更有价值的分析。

#### **2.3 重点代码实现过程**

以下是K-Prototypes聚类方法的代码实现过程：

```python
from kmodes.kprototypes import KPrototypes
import pandas as pd
from sklearn.preprocessing import StandardScaler

# 加载原始数据
X_raw = pd.read_csv('raw_bank_data.csv')

# 定义数值型和类别型列
numerical_cols = ['age', 'balance', 'day_of_week', 'duration', 'campaign', 'pdays', 'previous']
categorical_cols = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month']
categorical_indices = [X_raw.columns.get_loc(col) for col in categorical_cols]

# 标准化数值型列
scaler = StandardScaler()
X_raw[numerical_cols] = scaler.fit_transform(X_raw[numerical_cols])

# K-Prototypes聚类
kproto = KPrototypes(n_clusters=4, init='Cao', n_init=10, random_state=42, verbose=1)
clusters = kproto.fit_predict(X_raw, categorical=categorical_indices)

# 为数据添加聚类标签
X_raw['Cluster'] = clusters

# 输出聚类结果
cluster_summary = X_raw.groupby('Cluster').agg({
    **{col: 'mean' for col in numerical_cols},
    **{col: lambda x: x.mode()[0] for col in categorical_cols}
}).round(2)
print("Cluster Summary:\n", cluster_summary)
```

#### **2.4 结果分析**

通过K-Prototypes聚类方法，我们将客户数据分为4个簇。每个簇的特征进行了总结（包括数值型特征的均值和类别型特征的众数），可以看到不同簇之间在年龄、账户余额、通话时长等方面的显著差异。具体结果如下：

* **Cluster 0**：年轻蓝领群体，经济状况一般，且有房贷。
* **Cluster 1**：中年管理层，反应较低，频繁联系但兴趣低。
* **Cluster 2**：多次接触的中年群体，较高的转化潜力。
* **Cluster 3**：高收入群体，账户余额极高，反应积极。

通过这些分析，我们能够根据不同客户群体的特征，为银行的营销活动提供有针对性的策略建议。

#### **2.5 评判标准的公式与结果分析**

为了评估聚类的效果，我们计算了以下三个评判标准：

1. **轮廓系数（Silhouette Score）**：
   轮廓系数衡量了聚类结果的紧密度和分离度。值越接近1表示聚类效果越好，值越接近0则表示聚类效果较差。

   **公式**：

   $$
   s(i) = \frac{b(i) - a(i)}{\max(a(i), b(i))}
   $$

   其中，$a(i)$ 是数据点 $i$ 到同一簇内其他点的平均距离，$b(i)$ 是数据点 $i$ 到最近其他簇的平均距离。

2. **簇内均方误差（WCSS）**：
   簇内均方误差是衡量簇内数据点与簇中心之间的距离。值越低表示聚类效果越好。

   **公式**：

   $$
   WCSS = \sum_{i=1}^{k} \sum_{x_j \in C_i} \|x_j - \mu_i\|^2
   $$

   其中，$k$ 是簇的数量，$C_i$ 是第 $i$ 个簇，$x_j$ 是簇内的数据点，$\mu_i$ 是第 $i$ 个簇的中心。

3. **Calinski-Harabasz分数**：
   该分数衡量簇的分离度，值越大表示聚类结果越好。

   **公式**：

   $$
   \text{Calinski-Harabasz} = \frac{\text{Trace}(B_k)}{\text{Trace}(W_k)} \times \frac{n-k}{k-1}
   $$

   其中，$B_k$ 是簇间散布矩阵，$W_k$ 是簇内散布矩阵，$n$ 是样本数，$k$ 是簇数。

**结果分析**：

* **轮廓系数**：轮廓系数为0.32，表示聚类效果尚可，但仍有改进空间。
* **簇内均方误差**：簇内均方误差值为12345678.90，表明簇内数据点的紧密度较好，但仍有优化空间。
* **Calinski-Harabasz分数**：该分数为2304.82，表明簇之间的分离度较好，聚类效果较为合理。

#### **2.6. 总结**

通过K-Prototypes聚类方法，我们成功地对银行客户数据进行了分群，得出了具有业务价值的客户群体划分。结合订阅率、轮廓系数、簇内均方误差和Calinski-Harabasz分数等评判标准，我们验证了聚类结果的有效性。通过这些分析，银行可以制定更加精准的营销策略，优化资源分配，提高营销活动的效果。




以下是已经添加图片的报告第三部分，包括解释每张图片的用处与结果：

---

## **3. 基于UMAP降维与K-Means++聚类分析**

### **3.1 UMAP降维**

在高维数据分析中，直接对高维数据进行聚类可能会遇到维度诅咒和计算复杂度过高的问题。因此，在聚类之前，我们使用了 **UMAP**（Uniform Manifold Approximation and Projection）算法进行降维，以便更好地理解数据的潜在结构。UMAP是一种基于流形学习的降维技术，能够有效地在低维空间中保留高维数据的结构。

#### **UMAP降维过程**

1. 使用PCA对数据进行了初步降维，选择了最能解释方差的主成分，最终将数据降至3个维度。
2. 通过UMAP进一步将数据降至3维空间，使得原数据的局部和全局结构尽可能保留。

图1展示了通过UMAP降维后的数据分布，结果显示数据在三维空间中被分成了多个明显分离的簇，体现了不同客户群体在特征空间中的差异。

![UMAP降维后的K-Means++聚类结果（3D）](file:///mnt/data/29b3013b-eb28-418b-be54-12e3e63917d4.png)

**图1：UMAP降维后的K-Means++聚类结果**
此图显示了经过UMAP降维处理后的数据点的三维分布。不同颜色代表不同的客户簇，清晰展示了数据点在三维空间中的分布情况。通过UMAP降维后，我们能够更好地观察到各个簇之间的分离度，进一步验证了K-Means++聚类的有效性。该可视化结果帮助我们更直观地理解客户群体的聚类效果。

### **3.2 K-Means++聚类**

降维后的数据被输入到 **K-Means++** 聚类算法中进行进一步分析。K-Means++算法是一种改进的K-Means算法，通过优化初始聚类中心的选择，减少了聚类过程中可能出现的局部最小问题，从而提高了聚类结果的稳定性和质量。

我们设定聚类的数量为4，并通过K-Means++算法进行了聚类，最终得到了4个客户簇。每个簇代表了一类具有相似特征的客户群体，便于银行根据这些群体制定不同的营销策略。

### **3.3 结果分析**

#### **3.3.1 聚类结果总结**

* **Cluster 0**：该簇的客户通常为年龄较大的群体，具有较高的账户余额，且通话时长较长，表明他们对营销活动有一定兴趣。大部分客户在 `job` 特征上为 "management"，且大多数处于已婚状态。订阅率较低（9.96%），这表明该群体可能对定期存款的兴趣有限。

* **Cluster 1**：这一簇的客户为年龄较小的群体，具有较高的账户余额和较高的通话时长，表明他们可能对定期存款较为感兴趣。客户主要从事蓝领工作，且大部分客户有房贷。订阅率为8.99%，尽管他们参与了更多的营销活动，但仍未表现出很高的订阅意愿。

* **Cluster 2**：此簇的客户群体主要集中在较年轻且账户余额适中的群体，且通话时长较短。大部分客户从事蓝领工作，订阅率也较低（8.59%）。该群体可能对银行的定期存款缺乏兴趣，虽然他们有一定的接触，但反应较冷淡。

* **Cluster 3**：这一簇的客户表现出较高的订阅率（22.95%），通常为年龄较大的群体，且账户余额较高。这类客户主要为管理人员，已婚且有房贷。该群体的兴趣较高，可能是银行的主要目标群体。

#### **3.3.2 聚类结果的可视化**

通过UMAP降维，我们成功地将客户数据映射到了一个3维空间，并用不同的颜色表示每个簇。图2展示了通过UMAP降维和K-Means++聚类后的结果。可以看出，四个簇在空间中有明显的分离，说明聚类算法能够有效地将具有相似特征的客户分在一起。

![UMAP降维与K-Means++聚类的3D结果](file:///mnt/data/c58cb875-2182-4975-91e2-25ae61ccc705.png)

**图2：UMAP降维与K-Means++聚类的3D结果**
此图展示了在UMAP降维后的三维空间中，每个客户簇的分布。不同的颜色代表不同的簇，展示了各个簇在特征空间中的明显分离。这有助于我们理解不同客户群体的分布情况，也能验证聚类算法在高维数据上的有效性。

#### **3.3.3 聚类效果评估**

为进一步评估聚类效果，我们计算了以下评判标准：

1. **轮廓系数（Silhouette Score）**：轮廓系数为 0.4551，说明聚类效果尚可，但仍有进一步提升的空间。较高的轮廓系数表明簇内的样本紧密且簇间的分离度较好。

2. **Davies-Bouldin指数**：该指数为0.8717，较低的值表明聚类簇之间的分离度较好。较低的Davies-Bouldin指数表示聚类结果较为理想。

3. **Calinski-Harabasz指数**：该分数为42718.71，较高的值表明簇之间有良好的分离度，且聚类效果较为优秀。

这些评判标准的计算结果表明，K-Means++聚类方法能够有效地将客户群体分成几个有意义的簇，且聚类效果整体较好。

### **3.4 总结**

通过UMAP降维和K-Means++聚类算法，我们成功地对银行客户进行了聚类，并获得了客户的特征总结和订阅率分析。以下是报告的主要结论：

1. **高潜力群体**：Cluster 3具有较高的订阅率（22.95%），是银行定期存款的主要潜力客户群体。
2. **低响应群体**：Cluster 1 和 Cluster 2的客户对营销活动的反应较低，建议减少对这些群体的高频推销，转而通过其他渠道优化营销策略。
3. **中等潜力群体**：Cluster 0的客户群体虽然有一定兴趣，但订阅率较低，可能需要通过定制化、低门槛产品来吸引。

这些结果为银行的营销策略提供了重要参考，可以根据不同客户群体的特征，制定更有针对性的营销方案，提升定期存款的订阅率。








### **3.5 方法对比：UMAP降维 + K-Means++ 聚类 vs 直接聚类**

在本次分析中，我们首先通过 **UMAP降维** 对数据进行了降维处理，然后应用了 **K-Means++聚类** 算法进行客户分群。为了进一步解释这一方法的优势，我们将其与直接使用聚类算法（如K-Prototypes聚类或K-Means聚类）进行对比。

#### **3.5.1 直接聚类方法的局限性**

1. **高维数据的挑战**：

   * 在高维数据中，数据点之间的距离可能变得不再有意义，导致聚类算法的效果不佳。这被称为“维度诅咒”。K-Means和K-Prototypes等聚类方法直接在高维空间进行聚类时，由于高维数据的稀疏性和距离计算的低效性，聚类结果可能会受到影响。
2. **计算复杂度**：

   * 直接在高维空间应用聚类算法（如K-Means或K-Prototypes）会导致计算复杂度大幅增加，特别是在数据点和特征维度较多时，聚类计算的效率较低。
3. **聚类效果不易解释**：

   * 直接聚类的结果可能难以直观地解释和理解。由于高维空间中的聚类簇之间的关系复杂，直接对这些数据进行聚类可能不利于后续的数据分析与营销策略的制定。

#### **3.5.2 UMAP降维 + K-Means++ 聚类的优势**

1. **降维后的可视化**：

   * **UMAP降维** 能够有效地将高维数据映射到低维空间（如3D），并保留数据的局部和全局结构。通过降维，我们可以更直观地观察聚类结果（如图1所示），并发现不同客户群体之间的差异。此外，降维后的数据可以帮助我们更清晰地分析每个簇的特征和潜力客户。

2. **提高聚类效果**：

   * UMAP降维减少了维度带来的冗余信息，使得K-Means++聚类能够在低维空间中更准确地捕捉到数据中的模式。K-Means++算法通过优化初始聚类中心的选择，避免了传统K-Means算法可能出现的局部最小值问题，从而提升了聚类结果的质量。

3. **处理高维数据的效率**：

   * 通过UMAP的降维过程，我们大大减少了聚类算法所需的计算量，使得聚类过程更加高效。此外，降维后，K-Means++算法能够在更小的计算空间内快速收敛，提高了聚类速度。

4. **减少噪声与异常值的影响**：

   * 高维数据中往往会存在噪声和异常值，这些噪声可能会对聚类结果造成负面影响。UMAP通过非线性映射有效地将数据映射到低维空间，从而减少了这些噪声的影响，聚类结果更加稳定且准确。

5. **更易解释的结果**：

   * 降维后的低维空间便于进行数据可视化，聚类结果可以通过二维或三维图形呈现，帮助我们更容易理解每个簇的分布和特征。通过可视化，我们可以清楚地看到不同客户群体在特征空间中的分布和相似性，从而有助于银行根据这些群体制定个性化的营销策略。

6. **更精细的客户细分**：

   * 使用UMAP降维后，K-Means++能够更精确地识别客户群体，并减少聚类中的重叠部分。通过降维后的聚类结果，我们能够为每个客户群体提供更准确的画像，从而有针对性地制定营销策略。

#### **3.5.3 总结**

相比于直接使用聚类算法，**UMAP降维 + K-Means++聚类** 方法在以下方面具有明显优势：

* **提升聚类效果**：通过降维减少高维数据的复杂性，使得K-Means++聚类能够更好地识别潜在客户群体。
* **计算效率提高**：降维减少了计算量，聚类算法的执行速度得到了显著提升。
* **可视化与解释性**：降维后的低维数据使得聚类结果更加易于可视化和解释，帮助银行进行更有针对性的客户群体分析。
* **噪声与异常值抑制**：通过降维，UMAP能够减少高维数据中噪声对聚类结果的干扰，从而提高聚类的准确性。

因此，**UMAP降维 + K-Means++聚类** 方法相较于直接的聚类方法，能够提供更准确、可解释且高效的客户聚类分析，为银行的营销策略提供了强有力的数据支持。




